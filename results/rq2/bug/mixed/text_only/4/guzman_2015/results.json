{"ciurumelea_2017": {"test_loss": 0.4816846251487732, "test_accuracy": 0.8338658146964856, "test_f1": 0.723404255319149, "test_precision": 0.8192771084337349, "test_recall": 0.6476190476190476, "test_roc_auc": 0.889423076923077, "test_runtime": 0.3961, "test_samples_per_second": 790.171, "test_steps_per_second": 12.623}, "scalabrino_2017_RQ1": {"test_loss": 0.3601279854774475, "test_accuracy": 0.8662207357859532, "test_f1": 0.7368421052631579, "test_precision": 0.7368421052631579, "test_recall": 0.7368421052631579, "test_roc_auc": 0.915580009440642, "test_runtime": 0.91, "test_samples_per_second": 657.122, "test_steps_per_second": 10.989}, "scalabrino_2017_RQ3": {"test_loss": 0.68059903383255, "test_accuracy": 0.7464788732394366, "test_f1": 0.793103448275862, "test_precision": 0.92, "test_recall": 0.696969696969697, "test_roc_auc": 0.8595254874324643, "test_runtime": 0.2657, "test_samples_per_second": 534.347, "test_steps_per_second": 11.289}, "maalej_2016": {"test_loss": 0.5172154903411865, "test_accuracy": 0.8298611111111112, "test_f1": 0.3466666666666667, "test_precision": 0.3333333333333333, "test_recall": 0.3611111111111111, "test_roc_auc": 0.7821318342151675, "test_runtime": 0.6729, "test_samples_per_second": 428.006, "test_steps_per_second": 7.431}, "tizard_2019": {"test_loss": 0.4976666569709778, "test_accuracy": 0.803030303030303, "test_f1": 0.25906735751295334, "test_precision": 0.1984126984126984, "test_recall": 0.373134328358209, "test_roc_auc": 0.73084501619369, "test_runtime": 1.2435, "test_samples_per_second": 583.814, "test_steps_per_second": 9.65}, "williams_2017": {"test_loss": 0.6233968138694763, "test_accuracy": 0.7749360613810742, "test_f1": 0.4883720930232557, "test_precision": 0.6942148760330579, "test_recall": 0.37668161434977576, "test_roc_auc": 0.7922699888494029, "test_runtime": 0.551, "test_samples_per_second": 1419.311, "test_steps_per_second": 23.595}}