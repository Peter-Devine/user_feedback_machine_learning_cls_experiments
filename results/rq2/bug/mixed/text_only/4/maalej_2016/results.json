{"ciurumelea_2017": {"test_loss": 0.5610906481742859, "test_accuracy": 0.7380191693290735, "test_f1": 0.4142857142857143, "test_precision": 0.8285714285714286, "test_recall": 0.2761904761904762, "test_roc_auc": 0.8075549450549451, "test_runtime": 0.3968, "test_samples_per_second": 788.785, "test_steps_per_second": 12.6}, "guzman_2015": {"test_loss": 0.4600139558315277, "test_accuracy": 0.798175598631699, "test_f1": 0.4899135446685879, "test_precision": 0.5782312925170068, "test_recall": 0.425, "test_roc_auc": 0.7857385524372231, "test_runtime": 2.0478, "test_samples_per_second": 428.266, "test_steps_per_second": 6.837}, "scalabrino_2017_RQ1": {"test_loss": 0.4589928388595581, "test_accuracy": 0.782608695652174, "test_f1": 0.5075757575757576, "test_precision": 0.5982142857142857, "test_recall": 0.4407894736842105, "test_roc_auc": 0.808620486193061, "test_runtime": 0.9245, "test_samples_per_second": 646.825, "test_steps_per_second": 10.816}, "scalabrino_2017_RQ3": {"test_loss": 0.9073992371559143, "test_accuracy": 0.5140845070422535, "test_f1": 0.4888888888888888, "test_precision": 0.9166666666666666, "test_recall": 0.3333333333333333, "test_roc_auc": 0.6993187690862109, "test_runtime": 0.2687, "test_samples_per_second": 528.458, "test_steps_per_second": 11.165}, "tizard_2019": {"test_loss": 0.3458845615386963, "test_accuracy": 0.8815426997245179, "test_f1": 0.10416666666666666, "test_precision": 0.1724137931034483, "test_recall": 0.07462686567164178, "test_roc_auc": 0.6493782981903834, "test_runtime": 1.2484, "test_samples_per_second": 581.534, "test_steps_per_second": 9.612}, "williams_2017": {"test_loss": 0.5415354371070862, "test_accuracy": 0.7493606138107417, "test_f1": 0.3241379310344828, "test_precision": 0.7014925373134329, "test_recall": 0.21076233183856502, "test_roc_auc": 0.72053715395044, "test_runtime": 0.5532, "test_samples_per_second": 1413.669, "test_steps_per_second": 23.501}}