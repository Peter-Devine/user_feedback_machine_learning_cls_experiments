{"ciurumelea_2017": {"test_loss": 0.5592314004898071, "test_accuracy": 0.744408945686901, "test_f1": 0.6296296296296297, "test_precision": 0.5666666666666667, "test_recall": 0.7083333333333334, "test_roc_auc": 0.8106758832565284, "test_runtime": 0.6654, "test_samples_per_second": 470.428, "test_steps_per_second": 7.515}, "guzman_2015": {"test_loss": 0.5277189612388611, "test_accuracy": 0.7673888255416191, "test_f1": 0.6179775280898877, "test_precision": 0.49698795180722893, "test_recall": 0.8168316831683168, "test_roc_auc": 0.8573597359735974, "test_runtime": 2.0502, "test_samples_per_second": 427.761, "test_steps_per_second": 6.829}, "scalabrino_2017_RQ1": {"test_loss": 0.5291259288787842, "test_accuracy": 0.7625418060200669, "test_f1": 0.6120218579234973, "test_precision": 0.4827586206896552, "test_recall": 0.835820895522388, "test_roc_auc": 0.8733434122490993, "test_runtime": 1.4251, "test_samples_per_second": 419.621, "test_steps_per_second": 7.017}, "scalabrino_2017_RQ3": {"test_loss": 0.5556097626686096, "test_accuracy": 0.7605633802816901, "test_f1": 0.7976190476190476, "test_precision": 0.8701298701298701, "test_recall": 0.7362637362637363, "test_roc_auc": 0.8368886015944839, "test_runtime": 0.2161, "test_samples_per_second": 657.042, "test_steps_per_second": 13.881}, "maalej_2016": {"test_loss": 0.5841212272644043, "test_accuracy": 0.7256944444444444, "test_f1": 0.30088495575221236, "test_precision": 0.2, "test_recall": 0.6071428571428571, "test_roc_auc": 0.7524725274725275, "test_runtime": 0.5472, "test_samples_per_second": 526.313, "test_steps_per_second": 9.137}, "tizard_2019": {"test_loss": 0.513409435749054, "test_accuracy": 0.7575757575757576, "test_f1": 0.38028169014084506, "test_precision": 0.27835051546391754, "test_recall": 0.6, "test_roc_auc": 0.789011180992313, "test_runtime": 0.8477, "test_samples_per_second": 856.413, "test_steps_per_second": 14.156}}