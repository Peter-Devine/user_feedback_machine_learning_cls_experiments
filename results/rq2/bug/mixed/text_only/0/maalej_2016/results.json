{"ciurumelea_2017": {"test_loss": 0.5558810234069824, "test_accuracy": 0.7859424920127795, "test_f1": 0.6127167630057804, "test_precision": 0.6883116883116883, "test_recall": 0.5520833333333334, "test_roc_auc": 0.8452380952380951, "test_runtime": 0.665, "test_samples_per_second": 470.691, "test_steps_per_second": 7.519}, "guzman_2015": {"test_loss": 0.48086607456207275, "test_accuracy": 0.7913340935005702, "test_f1": 0.6098081023454157, "test_precision": 0.5355805243445693, "test_recall": 0.7079207920792079, "test_roc_auc": 0.845023835716905, "test_runtime": 2.0615, "test_samples_per_second": 425.417, "test_steps_per_second": 6.791}, "scalabrino_2017_RQ1": {"test_loss": 0.4743695855140686, "test_accuracy": 0.7892976588628763, "test_f1": 0.58, "test_precision": 0.5240963855421686, "test_recall": 0.6492537313432836, "test_roc_auc": 0.8446989191971178, "test_runtime": 1.4193, "test_samples_per_second": 421.349, "test_steps_per_second": 7.046}, "scalabrino_2017_RQ3": {"test_loss": 0.9303833842277527, "test_accuracy": 0.6549295774647887, "test_f1": 0.6754966887417219, "test_precision": 0.85, "test_recall": 0.5604395604395604, "test_roc_auc": 0.751131221719457, "test_runtime": 0.2107, "test_samples_per_second": 673.788, "test_steps_per_second": 14.235}, "tizard_2019": {"test_loss": 0.5006247162818909, "test_accuracy": 0.8168044077134986, "test_f1": 0.23121387283236994, "test_precision": 0.24096385542168675, "test_recall": 0.2222222222222222, "test_roc_auc": 0.6819706498951782, "test_runtime": 0.8472, "test_samples_per_second": 856.947, "test_steps_per_second": 14.164}, "williams_2017": {"test_loss": 0.6693258285522461, "test_accuracy": 0.7455242966751918, "test_f1": 0.40240240240240244, "test_precision": 0.6261682242990654, "test_recall": 0.29646017699115046, "test_roc_auc": 0.7447475647800343, "test_runtime": 0.5629, "test_samples_per_second": 1389.259, "test_steps_per_second": 23.095}}