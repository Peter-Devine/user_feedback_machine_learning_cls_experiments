{"ciurumelea_2017": {"test_loss": 0.4770255386829376, "test_accuracy": 0.7827476038338658, "test_f1": 0.6136363636363636, "test_precision": 0.675, "test_recall": 0.5625, "test_roc_auc": 0.8439900153609831, "test_runtime": 0.6636, "test_samples_per_second": 471.635, "test_steps_per_second": 7.534}, "scalabrino_2017_RQ1": {"test_loss": 0.348032146692276, "test_accuracy": 0.8461538461538461, "test_f1": 0.6933333333333334, "test_precision": 0.6265060240963856, "test_recall": 0.7761194029850746, "test_roc_auc": 0.9042878281008749, "test_runtime": 1.4023, "test_samples_per_second": 426.433, "test_steps_per_second": 7.131}, "scalabrino_2017_RQ3": {"test_loss": 0.6635379195213318, "test_accuracy": 0.6971830985915493, "test_f1": 0.718954248366013, "test_precision": 0.8870967741935484, "test_recall": 0.6043956043956044, "test_roc_auc": 0.8222365869424693, "test_runtime": 0.2117, "test_samples_per_second": 670.783, "test_steps_per_second": 14.171}, "maalej_2016": {"test_loss": 0.4043170213699341, "test_accuracy": 0.8229166666666666, "test_f1": 0.35443037974683544, "test_precision": 0.27450980392156865, "test_recall": 0.5, "test_roc_auc": 0.8135989010989011, "test_runtime": 0.5631, "test_samples_per_second": 511.431, "test_steps_per_second": 8.879}, "tizard_2019": {"test_loss": 0.4227468967437744, "test_accuracy": 0.8209366391184573, "test_f1": 0.34343434343434337, "test_precision": 0.3148148148148148, "test_recall": 0.37777777777777777, "test_roc_auc": 0.729350104821803, "test_runtime": 0.8478, "test_samples_per_second": 856.293, "test_steps_per_second": 14.154}, "williams_2017": {"test_loss": 0.4895268380641937, "test_accuracy": 0.7851662404092071, "test_f1": 0.5625, "test_precision": 0.6835443037974683, "test_recall": 0.4778761061946903, "test_roc_auc": 0.799675304004584, "test_runtime": 0.564, "test_samples_per_second": 1386.504, "test_steps_per_second": 23.049}}