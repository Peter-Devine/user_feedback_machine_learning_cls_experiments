{"ciurumelea_2017": {"test_loss": 0.6112951040267944, "test_accuracy": 0.7539936102236422, "test_f1": 0.6666666666666666, "test_precision": 0.6015625, "test_recall": 0.7475728155339806, "test_roc_auc": 0.8382801664355062, "test_runtime": 0.6609, "test_samples_per_second": 473.57, "test_steps_per_second": 7.565}, "guzman_2015": {"test_loss": 0.6925343871116638, "test_accuracy": 0.7103762827822121, "test_f1": 0.5822368421052632, "test_precision": 0.4306569343065693, "test_recall": 0.8984771573604061, "test_roc_auc": 0.8749328157659003, "test_runtime": 2.0628, "test_samples_per_second": 425.144, "test_steps_per_second": 6.787}, "scalabrino_2017_RQ1": {"test_loss": 0.585724949836731, "test_accuracy": 0.7625418060200669, "test_f1": 0.669767441860465, "test_precision": 0.5454545454545454, "test_recall": 0.8674698795180723, "test_roc_auc": 0.8851796073181616, "test_runtime": 1.4285, "test_samples_per_second": 418.628, "test_steps_per_second": 7.0}, "scalabrino_2017_RQ3": {"test_loss": 0.6845062971115112, "test_accuracy": 0.7535211267605634, "test_f1": 0.8148148148148148, "test_precision": 0.8191489361702128, "test_recall": 0.8105263157894737, "test_roc_auc": 0.7823068309070549, "test_runtime": 0.261, "test_samples_per_second": 543.993, "test_steps_per_second": 11.493}, "maalej_2016": {"test_loss": 0.6947746276855469, "test_accuracy": 0.7152777777777778, "test_f1": 0.359375, "test_precision": 0.23232323232323232, "test_recall": 0.7931034482758621, "test_roc_auc": 0.8017574224470776, "test_runtime": 0.6801, "test_samples_per_second": 423.438, "test_steps_per_second": 7.351}, "tizard_2019": {"test_loss": 0.6207586526870728, "test_accuracy": 0.7506887052341598, "test_f1": 0.3604240282685513, "test_precision": 0.2537313432835821, "test_recall": 0.6219512195121951, "test_roc_auc": 0.7658309347068626, "test_runtime": 0.8082, "test_samples_per_second": 898.332, "test_steps_per_second": 14.848}}