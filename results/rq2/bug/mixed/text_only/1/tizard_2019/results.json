{"ciurumelea_2017": {"test_loss": 0.8960723280906677, "test_accuracy": 0.7060702875399361, "test_f1": 0.3698630136986301, "test_precision": 0.627906976744186, "test_recall": 0.2621359223300971, "test_roc_auc": 0.7471104946833103, "test_runtime": 0.6584, "test_samples_per_second": 475.408, "test_steps_per_second": 7.594}, "guzman_2015": {"test_loss": 0.6290693879127502, "test_accuracy": 0.7605473204104903, "test_f1": 0.378698224852071, "test_precision": 0.45390070921985815, "test_recall": 0.3248730964467005, "test_roc_auc": 0.7547402209614811, "test_runtime": 2.0475, "test_samples_per_second": 428.332, "test_steps_per_second": 6.838}, "scalabrino_2017_RQ1": {"test_loss": 0.6576240658760071, "test_accuracy": 0.7809364548494984, "test_f1": 0.4780876494023905, "test_precision": 0.7058823529411765, "test_recall": 0.3614457831325301, "test_roc_auc": 0.7911786033020973, "test_runtime": 1.4099, "test_samples_per_second": 424.152, "test_steps_per_second": 7.093}, "scalabrino_2017_RQ3": {"test_loss": 1.56521737575531, "test_accuracy": 0.4295774647887324, "test_f1": 0.38167938931297707, "test_precision": 0.6944444444444444, "test_recall": 0.2631578947368421, "test_roc_auc": 0.6058230683090705, "test_runtime": 0.2771, "test_samples_per_second": 512.409, "test_steps_per_second": 10.826}, "maalej_2016": {"test_loss": 0.4549993872642517, "test_accuracy": 0.8298611111111112, "test_f1": 0.22222222222222224, "test_precision": 0.20588235294117646, "test_recall": 0.2413793103448276, "test_roc_auc": 0.6831314072693383, "test_runtime": 0.6759, "test_samples_per_second": 426.127, "test_steps_per_second": 7.398}, "williams_2017": {"test_loss": 0.7448068857192993, "test_accuracy": 0.7276214833759591, "test_f1": 0.4524421593830334, "test_precision": 0.5116279069767442, "test_recall": 0.4055299539170507, "test_roc_auc": 0.6775009175808491, "test_runtime": 0.5526, "test_samples_per_second": 1415.184, "test_steps_per_second": 23.526}}