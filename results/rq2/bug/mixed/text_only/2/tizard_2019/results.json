{"ciurumelea_2017": {"test_loss": 0.8901386857032776, "test_accuracy": 0.7092651757188498, "test_f1": 0.11650485436893204, "test_precision": 0.46153846153846156, "test_recall": 0.06666666666666667, "test_roc_auc": 0.6846537120079721, "test_runtime": 0.3982, "test_samples_per_second": 786.121, "test_steps_per_second": 12.558}, "guzman_2015": {"test_loss": 0.6232408881187439, "test_accuracy": 0.7924743443557583, "test_f1": 0.14953271028037385, "test_precision": 0.45714285714285713, "test_recall": 0.0893854748603352, "test_roc_auc": 0.7222311152374701, "test_runtime": 2.0524, "test_samples_per_second": 427.297, "test_steps_per_second": 6.821}, "scalabrino_2017_RQ1": {"test_loss": 0.6073639988899231, "test_accuracy": 0.7959866220735786, "test_f1": 0.2650602409638554, "test_precision": 0.7586206896551724, "test_recall": 0.16058394160583941, "test_roc_auc": 0.7744351378311192, "test_runtime": 1.4148, "test_samples_per_second": 422.683, "test_steps_per_second": 7.068}, "scalabrino_2017_RQ3": {"test_loss": 2.116358757019043, "test_accuracy": 0.3591549295774648, "test_f1": 0.13333333333333333, "test_precision": 1.0, "test_recall": 0.07142857142857142, "test_roc_auc": 0.6333487940630798, "test_runtime": 0.2747, "test_samples_per_second": 516.889, "test_steps_per_second": 10.92}, "maalej_2016": {"test_loss": 0.3031752109527588, "test_accuracy": 0.90625, "test_f1": 0.12903225806451613, "test_precision": 0.2857142857142857, "test_recall": 0.08333333333333333, "test_roc_auc": 0.7512626262626263, "test_runtime": 0.6845, "test_samples_per_second": 420.719, "test_steps_per_second": 7.304}, "williams_2017": {"test_loss": 0.7896566390991211, "test_accuracy": 0.7237851662404092, "test_f1": 0.14960629921259844, "test_precision": 0.6333333333333333, "test_recall": 0.08482142857142858, "test_roc_auc": 0.7035730286738352, "test_runtime": 0.4902, "test_samples_per_second": 1595.335, "test_steps_per_second": 26.521}}