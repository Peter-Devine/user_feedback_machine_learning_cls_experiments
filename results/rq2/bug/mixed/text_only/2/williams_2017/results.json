{"ciurumelea_2017": {"test_loss": 0.5871652960777283, "test_accuracy": 0.7476038338658147, "test_f1": 0.6255924170616113, "test_precision": 0.5454545454545454, "test_recall": 0.7333333333333333, "test_roc_auc": 0.7982062780269057, "test_runtime": 0.4, "test_samples_per_second": 782.522, "test_steps_per_second": 12.5}, "guzman_2015": {"test_loss": 0.5862178206443787, "test_accuracy": 0.7149372862029647, "test_f1": 0.558303886925795, "test_precision": 0.4082687338501292, "test_recall": 0.88268156424581, "test_roc_auc": 0.8595828464407487, "test_runtime": 2.0645, "test_samples_per_second": 424.809, "test_steps_per_second": 6.781}, "scalabrino_2017_RQ1": {"test_loss": 0.49923470616340637, "test_accuracy": 0.774247491638796, "test_f1": 0.6239554317548746, "test_precision": 0.5045045045045045, "test_recall": 0.8175182481751825, "test_roc_auc": 0.8688189749354782, "test_runtime": 1.4161, "test_samples_per_second": 422.299, "test_steps_per_second": 7.062}, "scalabrino_2017_RQ3": {"test_loss": 0.535530149936676, "test_accuracy": 0.7535211267605634, "test_f1": 0.8108108108108109, "test_precision": 0.8620689655172413, "test_recall": 0.7653061224489796, "test_roc_auc": 0.814935064935065, "test_runtime": 0.2729, "test_samples_per_second": 520.374, "test_steps_per_second": 10.994}, "maalej_2016": {"test_loss": 0.5793619751930237, "test_accuracy": 0.71875, "test_f1": 0.30769230769230765, "test_precision": 0.1935483870967742, "test_recall": 0.75, "test_roc_auc": 0.8038194444444444, "test_runtime": 0.683, "test_samples_per_second": 421.665, "test_steps_per_second": 7.321}, "tizard_2019": {"test_loss": 0.5285500884056091, "test_accuracy": 0.7699724517906336, "test_f1": 0.27705627705627706, "test_precision": 0.21333333333333335, "test_recall": 0.3950617283950617, "test_roc_auc": 0.6848310843142884, "test_runtime": 1.2498, "test_samples_per_second": 580.909, "test_steps_per_second": 9.602}}