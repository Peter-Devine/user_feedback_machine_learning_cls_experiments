{"ciurumelea_2017": {"test_loss": 0.48638999462127686, "test_accuracy": 0.7987220447284346, "test_f1": 0.622754491017964, "test_precision": 0.6753246753246753, "test_recall": 0.5777777777777777, "test_roc_auc": 0.8343796711509716, "test_runtime": 0.4086, "test_samples_per_second": 766.012, "test_steps_per_second": 12.237}, "guzman_2015": {"test_loss": 0.46539467573165894, "test_accuracy": 0.7730900798175598, "test_f1": 0.5683297180043384, "test_precision": 0.4645390070921986, "test_recall": 0.7318435754189944, "test_roc_auc": 0.8421907765203054, "test_runtime": 2.0526, "test_samples_per_second": 427.271, "test_steps_per_second": 6.821}, "scalabrino_2017_RQ1": {"test_loss": 0.3951120674610138, "test_accuracy": 0.8060200668896321, "test_f1": 0.6209150326797385, "test_precision": 0.5621301775147929, "test_recall": 0.6934306569343066, "test_roc_auc": 0.8741707174184967, "test_runtime": 1.4168, "test_samples_per_second": 422.065, "test_steps_per_second": 7.058}, "scalabrino_2017_RQ3": {"test_loss": 0.6835814714431763, "test_accuracy": 0.6971830985915493, "test_f1": 0.7624309392265194, "test_precision": 0.8313253012048193, "test_recall": 0.7040816326530612, "test_roc_auc": 0.7551020408163264, "test_runtime": 0.2742, "test_samples_per_second": 517.809, "test_steps_per_second": 10.94}, "tizard_2019": {"test_loss": 0.4630838632583618, "test_accuracy": 0.8140495867768595, "test_f1": 0.20118343195266272, "test_precision": 0.19318181818181818, "test_recall": 0.20987654320987653, "test_roc_auc": 0.639448751076658, "test_runtime": 1.2362, "test_samples_per_second": 587.296, "test_steps_per_second": 9.707}, "williams_2017": {"test_loss": 0.5845921635627747, "test_accuracy": 0.7378516624040921, "test_f1": 0.4757033248081841, "test_precision": 0.5568862275449101, "test_recall": 0.41517857142857145, "test_roc_auc": 0.7190940220174091, "test_runtime": 0.5088, "test_samples_per_second": 1537.04, "test_steps_per_second": 25.552}}