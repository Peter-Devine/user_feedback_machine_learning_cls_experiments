{"ciurumelea_2017": {"test_loss": 0.4753173291683197, "test_accuracy": 0.8274760383386581, "test_f1": 0.6351351351351352, "test_precision": 0.8103448275862069, "test_recall": 0.5222222222222223, "test_roc_auc": 0.8714000996512208, "test_runtime": 0.3987, "test_samples_per_second": 784.991, "test_steps_per_second": 12.54}, "scalabrino_2017_RQ1": {"test_loss": 0.325100302696228, "test_accuracy": 0.882943143812709, "test_f1": 0.7107438016528925, "test_precision": 0.819047619047619, "test_recall": 0.6277372262773723, "test_roc_auc": 0.9156388048830691, "test_runtime": 1.399, "test_samples_per_second": 427.451, "test_steps_per_second": 7.148}, "scalabrino_2017_RQ3": {"test_loss": 0.9066725373268127, "test_accuracy": 0.647887323943662, "test_f1": 0.691358024691358, "test_precision": 0.875, "test_recall": 0.5714285714285714, "test_roc_auc": 0.7956864564007422, "test_runtime": 0.2827, "test_samples_per_second": 502.364, "test_steps_per_second": 10.613}, "maalej_2016": {"test_loss": 0.3041476011276245, "test_accuracy": 0.8854166666666666, "test_f1": 0.32653061224489793, "test_precision": 0.32, "test_recall": 0.3333333333333333, "test_roc_auc": 0.8568497474747474, "test_runtime": 0.6744, "test_samples_per_second": 427.078, "test_steps_per_second": 7.415}, "tizard_2019": {"test_loss": 0.42009976506233215, "test_accuracy": 0.8526170798898072, "test_f1": 0.15748031496062992, "test_precision": 0.21739130434782608, "test_recall": 0.12345679012345678, "test_roc_auc": 0.6955115322040386, "test_runtime": 1.2413, "test_samples_per_second": 584.855, "test_steps_per_second": 9.667}, "williams_2017": {"test_loss": 0.649754524230957, "test_accuracy": 0.7595907928388747, "test_f1": 0.36054421768707484, "test_precision": 0.7571428571428571, "test_recall": 0.23660714285714285, "test_roc_auc": 0.7952428955453149, "test_runtime": 0.492, "test_samples_per_second": 1589.33, "test_steps_per_second": 26.421}}