{"ciurumelea_2017": {"test_loss": 0.4263419806957245, "test_accuracy": 0.8370607028753994, "test_f1": 0.6909090909090909, "test_precision": 0.6951219512195121, "test_recall": 0.6867469879518072, "test_roc_auc": 0.8935044525929806, "test_runtime": 0.6599, "test_samples_per_second": 474.291, "test_steps_per_second": 7.577}, "scalabrino_2017_RQ1": {"test_loss": 0.40220293402671814, "test_accuracy": 0.8545150501672241, "test_f1": 0.7128712871287128, "test_precision": 0.7346938775510204, "test_recall": 0.6923076923076923, "test_roc_auc": 0.8991617357001972, "test_runtime": 1.403, "test_samples_per_second": 426.237, "test_steps_per_second": 7.128}, "scalabrino_2017_RQ3": {"test_loss": 0.9343090057373047, "test_accuracy": 0.647887323943662, "test_f1": 0.7191011235955056, "test_precision": 0.9142857142857143, "test_recall": 0.5925925925925926, "test_roc_auc": 0.7949346405228759, "test_runtime": 0.2866, "test_samples_per_second": 495.479, "test_steps_per_second": 10.468}, "maalej_2016": {"test_loss": 0.4949285089969635, "test_accuracy": 0.84375, "test_f1": 0.3835616438356165, "test_precision": 0.32558139534883723, "test_recall": 0.4666666666666667, "test_roc_auc": 0.7926356589147286, "test_runtime": 0.4919, "test_samples_per_second": 585.5, "test_steps_per_second": 10.165}, "tizard_2019": {"test_loss": 0.5251134634017944, "test_accuracy": 0.7851239669421488, "test_f1": 0.3389830508474576, "test_precision": 0.273972602739726, "test_recall": 0.4444444444444444, "test_roc_auc": 0.7446191474493361, "test_runtime": 0.8131, "test_samples_per_second": 892.843, "test_steps_per_second": 14.758}, "williams_2017": {"test_loss": 0.5814641714096069, "test_accuracy": 0.7800511508951407, "test_f1": 0.4787878787878789, "test_precision": 0.6583333333333333, "test_recall": 0.3761904761904762, "test_roc_auc": 0.7867798867798868, "test_runtime": 0.5481, "test_samples_per_second": 1426.8, "test_steps_per_second": 23.719}}