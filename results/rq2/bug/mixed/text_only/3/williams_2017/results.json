{"ciurumelea_2017": {"test_loss": 0.6727643013000488, "test_accuracy": 0.7028753993610224, "test_f1": 0.6204081632653061, "test_precision": 0.4691358024691358, "test_recall": 0.9156626506024096, "test_roc_auc": 0.8486118386589837, "test_runtime": 0.6706, "test_samples_per_second": 466.72, "test_steps_per_second": 7.456}, "guzman_2015": {"test_loss": 0.8038142323493958, "test_accuracy": 0.6419612314709237, "test_f1": 0.5299401197604791, "test_precision": 0.37579617834394907, "test_recall": 0.8984771573604061, "test_roc_auc": 0.840952523141236, "test_runtime": 2.0496, "test_samples_per_second": 427.886, "test_steps_per_second": 6.831}, "scalabrino_2017_RQ1": {"test_loss": 0.7882766127586365, "test_accuracy": 0.657190635451505, "test_f1": 0.5790554414784393, "test_precision": 0.4259818731117825, "test_recall": 0.9038461538461539, "test_roc_auc": 0.8570889894419307, "test_runtime": 1.4192, "test_samples_per_second": 421.371, "test_steps_per_second": 7.046}, "scalabrino_2017_RQ3": {"test_loss": 0.5990936756134033, "test_accuracy": 0.7464788732394366, "test_f1": 0.8363636363636364, "test_precision": 0.8214285714285714, "test_recall": 0.8518518518518519, "test_roc_auc": 0.7167755991285403, "test_runtime": 0.2778, "test_samples_per_second": 511.188, "test_steps_per_second": 10.8}, "maalej_2016": {"test_loss": 0.8197787404060364, "test_accuracy": 0.6527777777777778, "test_f1": 0.31506849315068497, "test_precision": 0.19827586206896552, "test_recall": 0.7666666666666667, "test_roc_auc": 0.777906976744186, "test_runtime": 0.4966, "test_samples_per_second": 579.93, "test_steps_per_second": 10.068}, "tizard_2019": {"test_loss": 0.6657171249389648, "test_accuracy": 0.6818181818181818, "test_f1": 0.3529411764705882, "test_precision": 0.23595505617977527, "test_recall": 0.7, "test_roc_auc": 0.7709468902865129, "test_runtime": 0.822, "test_samples_per_second": 883.177, "test_steps_per_second": 14.598}}